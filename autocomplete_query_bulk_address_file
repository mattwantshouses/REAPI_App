# Script Name: Address Autocomplete Processor
# Version: 1.3

import requests
import json
import pandas as pd
import logging
from google.colab import files, userdata
from typing import List, Dict, Any
import time
from tqdm import tqdm

# 1. Configuration and Setup
# 1.1 Constants and API configuration
API_URL = "https://api.realestateapi.com/v2/AutoComplete"
BATCH_SIZE = 1
MAX_RETRIES = 3
DELAY_BETWEEN_CALLS = 0.005  # seconds

# 1.2 Logging setup
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# 2. Helper Functions
# 2.1 API key retrieval
def get_api_key() -> str:
    api_key = userdata.get('x-api-key')
    if not api_key:
        logger.warning("API key not found in Colab secrets. Prompting user for manual input.")
        api_key = input("Please enter your API key: ")
    if not api_key:
        raise ValueError("API key is required to proceed.")
    return api_key

# 2.2 API request function
def make_api_request(address: str) -> Dict[str, Any]:
    headers = {
        "x-user-id": "UniqueUserIdentifier",
        "content-type": "application/json",
        "x-api-key": get_api_key()
    }
    payload = {
        "ids_only": False,
        "obfuscate": False,
        "summary": False,
        "size": 50,
        "search_types": ["A"],
        "search": address
    }
    for attempt in range(MAX_RETRIES):
        try:
            response = requests.post(API_URL, json=payload, headers=headers)
            response.raise_for_status()
            return response.json()
        except requests.exceptions.RequestException as e:
            if isinstance(e, requests.exceptions.HTTPError) and e.response.status_code == 429:
                logger.warning(f"Rate limit exceeded (attempt {attempt + 1}/{MAX_RETRIES}): {str(e)}")
            else:
                logger.warning(f"Request failed (attempt {attempt + 1}/{MAX_RETRIES}): {str(e)}")
            time.sleep(DELAY_BETWEEN_CALLS * (attempt + 1))
    logger.error(f"Max retries reached for address: {address}")
    return {}

# 2.3 Process addresses in batches
def process_addresses(addresses: List[str]) -> List[Dict[str, Any]]:
    results = []
    total_addresses = len(addresses)
    for i in tqdm(range(total_addresses), desc="Processing addresses", unit="address"):
        address_line = addresses[i].strip().rstrip(',')  # Remove whitespace and trailing comma
        try:
            # Extract address using string manipulation instead of full JSON parsing
            address = address_line.split('"address": ')[1].strip('"').rstrip('}').strip()            
            result = make_api_request(address)
            results.append(result)
        except IndexError:
            logger.warning(f"Invalid format on line {i+1}: {address_line}")
            continue  # Skip this line and continue with the next
        time.sleep(DELAY_BETWEEN_CALLS)
    return results

# 2.4 Convert JSON results to DataFrame
def json_to_dataframe(results: List[Dict[str, Any]]) -> pd.DataFrame:
    flattened_data = []
    for result in results:
        if not result.get('data'):
            logger.warning(f"No data found for input: {result.get('input', {}).get('search', '')}")
            continue
        for item in result.get('data', []):
            flattened_item = {
                'input_address': result.get('input', {}).get('search', ''),
                'id': item.get('id', ''),
                'title': item.get('title', ''),
                'address': item.get('address', ''),
                'city': item.get('city', ''),
                'state': item.get('state', ''),
                'zip': item.get('zip', ''),
                'county': item.get('county', ''),
                'latitude': item.get('latitude', ''),
                'longitude': item.get('longitude', ''),
                'type': item.get('type', '')
            }
            flattened_data.append(flattened_item)
    return pd.DataFrame(flattened_data)

# 3. Main Execution
def main():
    try:
        # 3.1 File upload
        logger.info("Please upload your addresses.txt file")
        uploaded = files.upload()

        if not uploaded:
            logger.error("No file was uploaded. Exiting.")
            return

        file_name = next(iter(uploaded))
        
        # 3.2 Read addresses
        with open(file_name, 'r') as f:
            addresses = f.readlines()

        logger.info(f"Loaded {len(addresses)} addresses from {file_name}")

        # 3.3 Process addresses
        results = process_addresses(addresses)

        # 3.4 Convert to DataFrame
        df = json_to_dataframe(results)

        if df.empty:
            logger.warning("No valid results were obtained. The output CSV will be empty.")
        elif len(df) < len(addresses):
            logger.warning(f"Only {len(df)} out of {len(addresses)} addresses were successfully processed.")

        # 3.5 Save to CSV
        csv_filename = 'autocompleted_addresses.csv'
        df.to_csv(csv_filename, index=False)
        logger.info(f"Results saved to {csv_filename}")

        # 3.6 Download CSV
        files.download(csv_filename)
        logger.info(f"Download initiated for {csv_filename}")

    except Exception as e:
        logger.exception(f"An unexpected error occurred: {str(e)}")

if __name__ == "__main__":
    main()