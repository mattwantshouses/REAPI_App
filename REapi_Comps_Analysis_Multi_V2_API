# Script Name: REapi Comps Analysis
# Version: 2.6 (Multiple Addresses & Asynchronous Processing)
# Created: 09-13-24
# Updated: 04-27-24
# Handles importing multiple subject properties with multiple comps each
# adding price per sq ft to comps
# adjusted ppsf to aim towards the top 30% values after remove top 15%
# Next iteration: Improve asynchronous processing, enhance error handling

# 1. Import required libraries
import os
import json
import re
import asyncio
from datetime import datetime
from math import radians, sin, cos, sqrt, atan2
from typing import Dict, Any, Tuple, List

import pandas as pd
import numpy as np
import requests
from tqdm import tqdm
from google.colab import files
import concurrent.futures

# 2. Constants
OUTPUT_FOLDER = '/content/drive/MyDrive/'
DRIVE_FOLDER = 'REapi_Comps_Results'
COLAB_OUTPUT_FOLDER = '/content/REapi_Comps_Results'
DRIVE_OUTPUT_FOLDER = os.path.join(OUTPUT_FOLDER, DRIVE_FOLDER)

# Ensure the drive output folder exists
os.makedirs(DRIVE_OUTPUT_FOLDER, exist_ok=True)

print(f"Drive output folder set to: {DRIVE_OUTPUT_FOLDER}")


FIELDS_TO_KEEP = [
    'address', 'bedrooms', 'bathrooms', 'yearBuilt', 'squareFeet', 'lotSquareFeet',
    'lastSaleDate', 'lastSaleAmount', 'estimatedValue', 'latitude', 'longitude'
]

# 3. Helper functions
# 3.1 Flatten JSON
def flatten_json(nested_json: Dict[str, Any], prefix: str = '') -> Dict[str, Any]:
    """Recursively flatten a nested JSON structure."""
    flattened = {}
    for key, value in nested_json.items():
        new_key = f"{prefix}.{key}" if prefix else key
        if isinstance(value, dict):
            flattened.update(flatten_json(value, new_key))
        elif isinstance(value, list):
            for i, item in enumerate(value):
                if isinstance(item, dict):
                    flattened.update(flatten_json(item, f"{new_key}.{i}"))
                else:
                    flattened[f"{new_key}.{i}"] = item
        else:
            flattened[new_key] = value
    return flattened

# 3.2 Attempt to fix issues with JSON formatting
def attempt_json_fix(json_string: str) -> str:
    """Attempt to fix common JSON formatting issues."""
    # Replace single quotes with double quotes
    json_string = json_string.replace("'", '"')
    # Add quotes to keys without quotes
    json_string = re.sub(r'(\w+)(?=\s*:)', r'"\1"', json_string)
    # Replace None, True, and False with their JSON equivalents
    json_string = json_string.replace('None', 'null').replace('True', 'true').replace('False', 'false')
    # Remove trailing commas in objects and arrays
    json_string = re.sub(r',\s*}', '}', json_string)
    json_string = re.sub(r',\s*\]', ']', json_string)
    # Add missing commas between object properties
    json_string = re.sub(r'"\s*\n\s*"', '",\n"', json_string)
    return json_string

# 3.3 Remove PPSF outliers
def calculate_adjusted_arv(comps_data: pd.DataFrame, subject_sqft: float, outlier_percent: float = 0.15, top_percent: float = 0.30) -> tuple:
    """
    Calculate adjusted ARV focusing on top 30% of comps after removing top 15% outliers.
    
    :param comps_data: DataFrame containing the comp data with 'price_per_sqft' column
    :param subject_sqft: Square footage of the subject property
    :param outlier_percent: Percentage of top values to remove as outliers (default 15%)
    :param top_percent: Percentage of top remaining values to focus on (default 30%)
    :return: Tuple of (adjusted ARV, adjusted average PPSF)
    """
    # Sort PPSF in descending order
    sorted_ppsf = sorted(comps_data['price_per_sqft'], reverse=True)
    
    # Remove top 15% as outliers
    outlier_cutoff = int(len(sorted_ppsf) * outlier_percent)
    filtered_ppsf = sorted_ppsf[outlier_cutoff:]
    
    # Focus on top 30% of remaining data
    top_cutoff = int(len(filtered_ppsf) * top_percent)
    selected_ppsf = filtered_ppsf[:top_cutoff]
    
    # Calculate average PPSF from selected range
    avg_ppsf = np.mean(selected_ppsf)
    
    # Calculate adjusted ARV
    adjusted_arv = avg_ppsf * subject_sqft
    
    return adjusted_arv, avg_ppsf

# 4. Main functions

# 4.1 File selection
def select_file() -> str:
    """List files and allow user to select or upload a file."""
    files_list = [f for f in os.listdir() if f.endswith(('.json', '.txt', '.csv', '.xlsx', '.xls'))]
    print("Available files:")
    for i, file in enumerate(files_list, 1):
        print(f"{i}. {file}")
    print(f"{len(files_list) + 1}. Upload a new file")

    while True:
        try:
            choice = int(input("Select a file number: "))
            if 1 <= choice <= len(files_list):
                return files_list[choice - 1]
            if choice == len(files_list) + 1:
                uploaded = files.upload()
                if uploaded:
                    return list(uploaded.keys())[0]
                print("No file was uploaded. Please try again.")
            else:
                print("Invalid choice. Please try again.")
        except ValueError:
            print("Invalid input. Please enter a number.")

# 4.2 Data import and parsing
def import_data(file_path: str) -> List[Tuple[Dict[str, Any], pd.DataFrame]]:
    """Import data from various file formats, including JSON in .txt files."""
    subjects = []
    if file_path.endswith(('.json', '.txt')):
        with open(file_path, 'r') as f:
            content = f.read()
        try:
            data_list = json.loads(content)
        except json.JSONDecodeError as e:
            print(f"Initial JSON parsing failed: {str(e)}")
            print("Attempting to fix JSON formatting...")
            fixed_content = attempt_json_fix(content)
            try:
                data_list = json.loads(fixed_content)
                print("JSON successfully parsed after fixing.")
            except json.JSONDecodeError as e:
                print(f"JSON parsing failed even after attempted fix: {str(e)}")
                print("Printing the problematic section:")
                error_line = e.lineno
                start = max(0, error_line - 3)
                end = error_line + 2
                problematic_section = fixed_content.split('\n')[start:end]
                for i, line in enumerate(problematic_section, start=start+1):
                    print(f"{i}: {line}")
                print("\nPlease check the input file for formatting issues.")
                raise

        for data in data_list:
            if 'comps' in data and 'input' in data:
                subject_data = data['input']
                flattened_data = [flatten_json(comp) for comp in data['comps']]
                df = pd.DataFrame(flattened_data)
                subjects.append((subject_data, df))
            else:
                print("JSON entry does not contain 'comps' and 'input' keys. Skipping this entry.")
    elif file_path.endswith('.csv'):
        df = pd.read_csv(file_path)
        subjects.append(df)
    elif file_path.endswith(('.xlsx', '.xls')):
        df = pd.read_excel(file_path)
        subjects.append(df)
    else:
        raise ValueError("Unsupported file format")

    return subjects

# 4.3 Data cleaning and preprocessing
def clean_data(df: pd.DataFrame) -> pd.DataFrame:
    """Clean and preprocess the data."""
    df = df.fillna(0)
    numeric_columns = [col for col in df.columns if any(field in col for field in [
        'bedrooms', 'bathrooms', 'yearBuilt', 'squareFeet', 'lotSquareFeet', 
        'lastSaleAmount', 'latitude', 'longitude'
    ])]
    for col in numeric_columns:
        df[col] = pd.to_numeric(df[col], errors='coerce')
    return df

# 4.4 Price per square foot calculation
def calculate_ppsf(df: pd.DataFrame) -> pd.DataFrame:
    """Calculate price per square foot."""
    df['price_per_sqft'] = df['lastSaleAmount'] / df['squareFeet']
    return df

# 4.5 Distance calculation
def calculate_distance(lat1: float, lon1: float, lat2: float, lon2: float) -> float:
    """Calculate the distance between two points on Earth in miles."""
    radius = 3959  # Earth's radius in miles

    lat1, lon1, lat2, lon2 = map(radians, [lat1, lon1, lat2, lon2])
    dlat = lat2 - lat1
    dlon = lon2 - lon1

    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2
    c = 2 * atan2(sqrt(a), sqrt(1-a))
    distance = radius * c

    return distance

# 4.6 Results formatting
def format_results(subject_data: Dict[str, Any], comps_data: pd.DataFrame, est_arv: float, avg_ppsf: float) -> pd.DataFrame:
    """Format the results into a DataFrame."""
    results = {
        'subject_address': subject_data.get('address', 'N/A'),
        'subject_beds': subject_data.get('bedrooms', 'N/A'),
        'subject_baths': subject_data.get('bathrooms', 'N/A'),
        'subject_year_built': subject_data.get('yearBuilt', 'N/A'),
        'subject_sqft': round(float(subject_data.get('squareFeet', 0)), 2),
        'subject_lot_size': round(float(subject_data.get('lotSquareFeet', 0)), 2),
        'est_arv': round(est_arv, 2),
        'avg_ppsf': round(avg_ppsf, 2),
        'num_comps': len(comps_data)
    }
    # Calculate and add PPSF for each comp
    for i, comp in comps_data.iterrows():
        comp_prefix = f'comp_{i+1}_'
        sold_price = comp.get('lastSaleAmount', 0)
        square_feet = comp.get('squareFeet', 0)
        if square_feet > 0:
            ppsf = round(sold_price / square_feet, 2)
        else:
            ppsf = 0
        results[f'{comp_prefix}ppsf'] = ppsf

    for i, comp in comps_data.iterrows():
        comp_prefix = f'comp_{i+1}_'
        results[f'{comp_prefix}address'] = comp.get('address.address', 'N/A')
        for field in FIELDS_TO_KEEP:
            if field != 'address':
                value = comp.get(field, 'N/A')
                if field in ['latitude', 'longitude']:
                    results[f'{comp_prefix}{field}'] = value
                elif isinstance(value, (int, float)):
                    results[f'{comp_prefix}{field}'] = round(float(value), 2)
                else:
                    results[f'{comp_prefix}{field}'] = value
        results[f'{comp_prefix}distance_miles'] = round(float(comp.get('distance_from_subject', 0)), 2)

    return pd.DataFrame([results])

# 4.7 Results saving
def save_results(df: pd.DataFrame) -> None:
    """Save results to CSV in both Colab and Google Drive, and download to local machine."""
    timestamp = datetime.now().strftime("%m%d%y_%H%M%S")
    filename = f"REAPI_Comps_{timestamp}.csv"

    colab_path = os.path.join(COLAB_OUTPUT_FOLDER, filename)
    os.makedirs(COLAB_OUTPUT_FOLDER, exist_ok=True)
    df.to_csv(colab_path, index=False)
    print(f"Results saved in Colab as {colab_path}")

    drive_path = os.path.join(OUTPUT_FOLDER, filename)
    os.makedirs(OUTPUT_FOLDER, exist_ok=True)
    df.to_csv(drive_path, index=False)
    print(f"Results saved to Google Drive as {drive_path}")

    files.download(colab_path)
    print(f"Results downloaded to your local machine as {filename}")
    print("Please check your browser's download folder for the file.")

# 4.8 Process a single subject
def process_subject(subject_data: Dict[str, Any], comps_df: pd.DataFrame) -> pd.DataFrame:
    """Process a single subject property and its comps."""
    try:
        df = clean_data(comps_df)
        df = calculate_ppsf(df)

        # Calculate initial average PPSF and ARV
        initial_avg_ppsf = df['price_per_sqft'].mean()
        subject_sqft = float(subject_data.get('squareFeet', 0))
        initial_est_arv = initial_avg_ppsf * subject_sqft if subject_sqft else 0

        # Calculate adjusted ARV
        adjusted_arv, adjusted_avg_ppsf = calculate_adjusted_arv(df, subject_sqft)

        subject_lat = float(subject_data.get('latitude', 0))
        subject_lon = float(subject_data.get('longitude', 0))
        df['distance_from_subject'] = df.apply(
            lambda row: calculate_distance(
                subject_lat, subject_lon, 
                float(row['latitude']), float(row['longitude'])
            ), 
            axis=1
        )

        results_df = format_results(subject_data, df, adjusted_arv, adjusted_avg_ppsf)

        print(f"Processed subject at {subject_data.get('address', 'N/A')}")
        print(f"Initial Estimated ARV: ${initial_est_arv:.2f}")
        print(f"Initial Average Price per Square Foot: ${initial_avg_ppsf:.2f}")
        print(f"Adjusted Estimated ARV: ${adjusted_arv:.2f}")
        print(f"Adjusted Average Price per Square Foot: ${adjusted_avg_ppsf:.2f}")
        print("-" * 50)

        return results_df

    except Exception as e:
        print(f"An error occurred while processing subject at {subject_data.get('address', 'N/A')}: {str(e)}")
        return pd.DataFrame()  # Return empty DataFrame on error

# 5. Main execution function
def main():
    """Main execution function."""
    try:
        file_path = select_file()
        subjects = import_data(file_path)

        all_results = []

        with concurrent.futures.ThreadPoolExecutor() as executor:
            # Submit all subjects to the executor
            future_to_subject = {
                executor.submit(process_subject, subject, comps): subject for subject, comps in subjects
            }

            # As each thread completes, append the result
            for future in tqdm(concurrent.futures.as_completed(future_to_subject), total=len(future_to_subject), desc="Processing Subjects"):
                result = future.result()
                if not result.empty:
                    all_results.append(result)

        if all_results:
            combined_df = pd.concat(all_results, ignore_index=True)
            save_results(combined_df)
            print(f"Processed {len(all_results)} subject properties.")
        else:
            print("No results to save.")

    except Exception as e:
        print(f"An error occurred: {str(e)}")

if __name__ == "__main__":
    main()
