# Script Name: REAPI Property Detail Retrieval with Pagination and CSV Output
# Version: 1.8

import requests
import json
import logging
import pandas as pd
from typing import Dict, Any, List
from google.colab import userdata, files
from datetime import datetime
import pytz
import io
import os
import time
#from pandas.io.json import json_normalize

# 1. Configuration and Setup
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

API_URL = "https://api.realestateapi.com/v2/PropertyDetail"
API_KEY = userdata.get('x-api-key')

if not API_KEY:
    raise ValueError("API key not found in Colab secrets. Please set the 'x-api-key' secret.")

# 2. Helper Functions
# 2.1 API Request Function
def make_api_request(payload: Dict[str, Any]) -> Dict[str, Any]:
    """Make an API request and return the JSON response."""
    headers = {
        "accept": "application/json",
        "x-user-id": "UniqueUserIdentifier",
        "content-type": "application/json",
        "x-api-key": API_KEY
    }
    try:
        response = requests.post(API_URL, json=payload, headers=headers)
        response.raise_for_status()
        json_response = response.json()
        if 'error' in json_response or 'errors' in json_response:
            logger.warning(f"API returned an error for payload: {payload}")
            logger.warning(f"Error response: {json_response}")
            return None
        return json_response
    except requests.RequestException as e:
        logger.error(f"API request failed: {str(e)}")
        if hasattr(e, 'response') and e.response is not None:
            logger.error(f"Response content: {e.response.text}")
        return None

# 2.2 File Selection Function
def select_ids_file() -> str:
    """Allow user to select the IDs file or upload a new one."""
    files_list = [f for f in os.listdir() if f.startswith('ids_only_') and f.endswith('.json')]

    if not files_list:
        print("No existing IDs files found. Please upload a file.")
        uploaded = files.upload()
        return list(uploaded.keys())[0]

    print("Available IDs files:")
    for i, file in enumerate(files_list, 1):
        print(f"{i}. {file}")

    while True:
        choice = input("Enter the number of the file to use, or 'u' to upload a new file: ")
        if choice.lower() == 'u':
            uploaded = files.upload()
            return list(uploaded.keys())[0]
        try:
            index = int(choice) - 1
            if 0 <= index < len(files_list):
                return files_list[index]
        except ValueError:
            pass
        print("Invalid choice. Please try again.")

# 2.3 Load IDs Function
def load_ids(filename: str) -> List[str]:
    """Load property IDs from the selected file."""
    _, ext = os.path.splitext(filename)
    if ext == '.json':
        with open(filename, 'r') as f:
            data = json.load(f)
            return data if isinstance(data, list) else list(data.values())[0]
    elif ext in ['.csv', '.txt']:
        df = pd.read_csv(filename, header=None)
        return df.iloc[:, 0].tolist()  # Always use the first column
    else:
        raise ValueError(f"Unsupported file format: {ext}")

# 2.4 Pagination Function
def paginated_property_detail_retrieval(ids: List[str], batch_size: int = 50) -> List[Dict[str, Any]]:
    """Retrieve property details with pagination."""
    all_results = []
    total_ids = len(ids)
    
    for i in range(0, total_ids, batch_size):
        batch = ids[i:i+batch_size]
        logger.info(f"Processing batch {i//batch_size + 1} of {(total_ids + batch_size - 1)//batch_size}")
        
        for property_id in batch:
            payload = {"id": property_id}
            response = make_api_request(payload)
            # Check if the response is not None before appending
            if response is not None: 
                all_results.append(response)
            
            # Add a small delay to avoid overwhelming the API
            time.sleep(0.5)
    
    return all_results



# 3. Main Execution
def main():
    # 3.1 Select and load property IDs
    ids_file = select_ids_file()
    property_ids = load_ids(ids_file)
    logger.info(f"Loaded {len(property_ids)} property IDs from {ids_file}")

    # 3.2 Retrieve property details with pagination
    property_details = paginated_property_detail_retrieval(property_ids)

    # 3.2 Retrieve property details with pagination
property_details = paginated_property_detail_retrieval(property_ids)

# 3.3 Create preview of first 5 responses
preview_data = property_details[:5]

# 3.4 Function to flatten nested JSON for preview
def flatten_for_preview(d):
    flat = {}
    for key, value in d.items():
        if isinstance(value, dict):
            for subkey, subvalue in value.items():
                flat[f"{key}_{subkey}"] = subvalue
        else:
            flat[key] = value
    return flat

# 3.5 Flatten preview data
flattened_preview = [flatten_for_preview(item) for item in preview_data]

# 3.6 Create DataFrame from flattened preview data
preview_df = pd.DataFrame(flattened_preview)

# 3.7 Print preview
print("\nPreview of first 5 responses:")
print(preview_df.to_string())


    # 3.8 Generate timestamp and filename components
    est_tz = pytz.timezone('US/Eastern')
    current_datetime = datetime.now(est_tz)
    date_str = current_datetime.strftime("%m%d%y")
    time_str = current_datetime.strftime("%H%M")

    # Create a summary based on the number of property IDs processed
    query_summary = f"{len(property_ids)}_properties"

    # 3.9 Save JSON response
    json_filename = f"PD_{date_str}{time_str}_{query_summary}.json"
    with open(json_filename, 'w') as f:
        json.dump(property_details, f)
    print(f"JSON response saved in Colab: {json_filename}")

if __name__ == "__main__":
    main()