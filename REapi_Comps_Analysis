# Script Name: REapi Comps Analysis
# Version: 1.2
# Created: 09-13-24
# Updated: 09-14-24
# Handles importing 1 subject property with multiple comps
# Next iteration: Handle multiple subject properties with multiple comps each, Async

# 1. Imports
import pandas as pd
import json
import os
from datetime import datetime
from math import radians, sin, cos, sqrt, atan2
import requests
from typing import Dict, Any, List, Optional
from tqdm import tqdm

# 1.1. Colab-specific imports
try:
    from google.colab import files, userdata
except ImportError:
    print("Running outside of Colab environment")

# 2. Constants
# 2.1. File paths and API configuration
OUTPUT_FOLDER = '/content/drive/MyDrive/REapi_Comps_Results'
COLAB_OUTPUT_FOLDER = '/content/REapi_Comps_Results'

# 3. Helper Functions
# 3.1. Recursive JSON flattening
def flatten_json(nested_json: Dict[str, Any], prefix: str = '') -> Dict[str, Any]:
    """Recursively flatten a nested JSON structure."""
    flattened = {}
    for key, value in nested_json.items():
        new_key = f"{prefix}.{key}" if prefix else key
        if isinstance(value, dict):
            flattened.update(flatten_json(value, new_key))
        elif isinstance(value, list):
            for i, item in enumerate(value):
                if isinstance(item, dict):
                    flattened.update(flatten_json(item, f"{new_key}.{i}"))
                else:
                    flattened[f"{new_key}.{i}"] = item
        else:
            flattened[new_key] = value
    return flattened
# 3.2. File selection
def select_file() -> str:
    """List files and allow user to select or upload a file."""
    files_list = [f for f in os.listdir() if f.endswith(('.json', '.txt', '.csv', '.xlsx', '.xls'))]
    print("Available files:")
    for i, file in enumerate(files_list, 1):
        print(f"{i}. {file}")
    print(f"{len(files_list) + 1}. Upload a new file")
    
    while True:
        try:
            choice = int(input("Select a file number: "))
            if 1 <= choice <= len(files_list):
                return files_list[choice - 1]
            elif choice == len(files_list) + 1:
                uploaded = files.upload()
                if uploaded:
                    return list(uploaded.keys())[0]
                else:
                    print("No file was uploaded. Please try again.")
            else:
                print("Invalid choice. Please try again.")
        except ValueError:
            print("Invalid input. Please enter a number.")

# 3.3. Data import (further modified)
def import_data(file_path: str) -> pd.DataFrame:
    """Import data from various file formats, including JSON in .txt files."""
    if file_path.endswith(('.json', '.txt')):
        with open(file_path, 'r') as f:
            try:
                data = json.load(f)
            except json.JSONDecodeError:
                # If JSON decoding fails, try to read as plain text
                f.seek(0)
                text_content = f.read()
                # Attempt to parse the text content as JSON
                try:
                    data = json.loads(text_content)
                except json.JSONDecodeError:
                    raise ValueError(f"Unable to parse JSON from file: {file_path}")

        # Process the JSON data
        if 'comps' in data:
            flattened_data = [flatten_json(comp) for comp in data['comps']]
            df = pd.DataFrame(flattened_data)
            # Add subject property information
            subject_info = flatten_json(data.get('input', {}))
            for key, value in subject_info.items():
                df[f'subject_{key}'] = value
            return df
        else:
            raise ValueError("JSON does not contain 'comps' key")

    elif file_path.endswith('.csv'):
        return pd.read_csv(file_path)
    elif file_path.endswith(('.xlsx', '.xls')):
        return pd.read_excel(file_path)
    else:
        raise ValueError("Unsupported file format")

# 3.4. Data cleaning (modified)
def clean_data(df: pd.DataFrame) -> pd.DataFrame:
    """Clean and preprocess the data."""
    df = df.fillna(0)
    numeric_columns = [col for col in df.columns if any(field in col for field in ['bedrooms', 'bathrooms', 'yearBuilt', 'squareFeet', 'lotSquareFeet', 'lastSaleAmount', 'latitude', 'longitude'])]
    for col in numeric_columns:
        df[col] = pd.to_numeric(df[col], errors='coerce')
    return df

# 3.5. Price per square foot calculation (modified)
def calculate_ppsf(df: pd.DataFrame) -> pd.DataFrame:
    """Calculate price per square foot."""
    sale_amount_col = next((col for col in df.columns if 'lastSaleAmount' in col), None)
    sqft_col = next((col for col in df.columns if 'squareFeet' in col), None)
    if sale_amount_col and sqft_col:
        df['price_per_sqft'] = df[sale_amount_col] / df[sqft_col]
    else:
        print("Warning: Unable to calculate price per square foot due to missing columns")
    return df

# 3.6. Results formatting (modified)
def format_results(subject_data: Dict[str, Any], comps_data: pd.DataFrame, est_arv: float, avg_ppsf: float) -> pd.DataFrame:
    """Format the results into a DataFrame."""
    results = {
        'subject_address': subject_data.get('address', 'N/A'),
        'subject_beds': subject_data.get('bedrooms', 'N/A'),
        'subject_baths': subject_data.get('bathrooms', 'N/A'),
        'subject_year_built': subject_data.get('yearBuilt', 'N/A'),
        'subject_sqft': subject_data.get('squareFeet', 'N/A'),
        'subject_lot_size': subject_data.get('lotSquareFeet', 'N/A'),
        'est_arv': est_arv,
        'avg_ppsf': avg_ppsf,
        'num_comps': len(comps_data)
    }
    
    for i, comp in comps_data.iterrows():
        comp_prefix = f'comp_{i+1}_'
        for col in comp.index:
            results[comp_prefix + col] = comp[col]
    
    return pd.DataFrame([results])

# 3.7. Results saving
def save_results(df: pd.DataFrame) -> None:
    """Save results to CSV in both Colab and Google Drive, and download to local machine."""
    timestamp = datetime.now().strftime("%m%d%y_%H%M%S")
    filename = f"REAPI_Comps_{timestamp}.csv"
    
    # Save in Colab environment
    colab_path = os.path.join(COLAB_OUTPUT_FOLDER, filename)
    os.makedirs(COLAB_OUTPUT_FOLDER, exist_ok=True)
    df.to_csv(colab_path, index=False)
    print(f"Results saved in Colab as {colab_path}")
    
    # Save to Google Drive
    drive_path = os.path.join(OUTPUT_FOLDER, filename)
    os.makedirs(OUTPUT_FOLDER, exist_ok=True)
    df.to_csv(drive_path, index=False)
    print(f"Results saved to Google Drive as {drive_path}")
    
    # Download to local machine
    files.download(colab_path)
    print(f"Results downloaded to your local machine as {filename}")
    print("Please check your browser's download folder for the file.")
# 4. Main Function (modified)
def main():
    """Main execution function."""
    try:
        # 4.1. File selection and data import
        file_path = select_file()
        df = import_data(file_path)
        
        # 4.2. Data cleaning and processing
        df = clean_data(df)
        df = calculate_ppsf(df)
        
        # 4.3. Extract subject property data
        subject_columns = [col for col in df.columns if col.startswith('subject_')]
        subject_data = df[subject_columns].iloc[0].to_dict()
        
        # Remove subject columns from the main dataframe
        df = df.drop(columns=subject_columns)
        
        # 4.4. Calculations
        avg_ppsf = df['price_per_sqft'].mean() if 'price_per_sqft' in df.columns else 0
        subject_sqft = float(subject_data.get('subject_squareFeet', 0))
        est_arv = avg_ppsf * subject_sqft if subject_sqft else 0
        
        # 4.5. Distance calculation
        lat_col = next((col for col in df.columns if 'latitude' in col), None)
        lon_col = next((col for col in df.columns if 'longitude' in col), None)
        if lat_col and lon_col:
            subject_lat = float(subject_data.get('subject_latitude', 0))
            subject_lon = float(subject_data.get('subject_longitude', 0))
            df['distance_from_subject'] = df.apply(lambda row: calculate_distance(subject_lat, subject_lon, float(row[lat_col]), float(row[lon_col])), axis=1)
        
        # 4.6. Results formatting and saving
        results_df = format_results(subject_data, df, est_arv, avg_ppsf)
        save_results(results_df)
        
        # 4.7. Print summary
        print(f"Processed {len(df)} comparable properties.")
        print(f"Estimated ARV: ${est_arv:.2f}")
        print(f"Average Price per Square Foot: ${avg_ppsf:.2f}")

    except Exception as e:
        print(f"An error occurred: {str(e)}")

# 5. API Request Function (if needed)
def make_api_request(endpoint: str, payload: Dict[str, Any]) -> Dict[str, Any]:
    """Make an API request to the specified endpoint."""
    try:
        api_key = userdata.get('reapi_key')
    except NameError:
        api_key = input("Please enter your API key: ")
    headers = {
        "accept": "application/json",
        "content-type": "application/json",
        "x-api-key": api_key
    }
    response = requests.post(endpoint, json=payload, headers=headers)
    return response.json()

# 6. Script Execution
if __name__ == "__main__":
    main()